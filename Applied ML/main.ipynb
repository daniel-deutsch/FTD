{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applied Machine Learning: Credit Card Approval Prediction\n",
    "\n",
    "*By Daniel Deutsch and Jos√© Lucas Barretto*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matplotlib styles\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams.update({\n",
    "    'figure.figsize': (15, 4),\n",
    "    'axes.prop_cycle': plt.cycler(color=[\"#4C72B0\", \"#C44E52\", \"#55A868\", \"#8172B2\", \"#CCB974\", \"#64B5CD\"]),\n",
    "    'axes.facecolor': \"#EAEAF2\"\n",
    "})\n",
    "\n",
    "# random state\n",
    "random_state=42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing\n",
    "\n",
    "At this staage the goal is to read both datasets and adapt its content for our classification models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing raw data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Credit records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reads the dataset\n",
    "df_credit_record = pd.read_csv(\"./datasets/credit_record.csv\")\n",
    "\n",
    "# Renames columns\n",
    "df_credit_record.rename(columns=str.lower, inplace=True)\n",
    "\n",
    "# Numericalize status\n",
    "df_credit_record.replace({'status': {'X': 0, 'C': 0, '0': 1, '1': 2, '2': 3, '3': 4, '4': 5, '5': 6}}, inplace=True)\n",
    "\n",
    "# Calculates the metric\n",
    "df_credit_record = df_credit_record.groupby('id')['status'].mean().reset_index()\n",
    "\n",
    "# Sets the label\n",
    "df_credit_record['is_good'] = 1*(df_credit_record['status'] <= 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Application Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reads the dataset\n",
    "df_application_record = pd.read_csv(\"./datasets/application_record.csv\")\n",
    "\n",
    "# Renames columns\n",
    "df_application_record.rename(columns=str.lower, inplace=True)\n",
    "\n",
    "# numericalyze and rename education level\n",
    "df_application_record.replace({\n",
    "    'name_education_type': {\n",
    "        'Higher education': 4,\n",
    "        'Academic degree': 4,\n",
    "        'Incomplete higher': 3,\n",
    "        'Secondary / secondary special': 2,\n",
    "        'Lower secondary': 1, \n",
    "    }\n",
    "}, inplace=True)\n",
    "df_application_record.rename(columns={'name_education_type': 'education_level'}, inplace=True)\n",
    "\n",
    "# transform days employed into is_unemployed\n",
    "df_application_record['is_unemployed'] = 1*(df_application_record['days_employed'] > 0)\n",
    "\n",
    "# drop uninteresting columns - birthday, days employed\n",
    "df_application_record.drop(columns=['days_employed', 'days_birth'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merging data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df_credit_record, df_application_record, how='inner', on='id')\n",
    "\n",
    "del df_credit_record, df_application_record"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define categorical, numerical, and other interesting vars\n",
    "categorical = [\n",
    "    'code_gender', \n",
    "    'flag_own_car', \n",
    "    'flag_own_realty', \n",
    "    'name_income_type',\n",
    "    'name_family_status', \n",
    "    'name_housing_type', \n",
    "    'flag_mobil', \n",
    "    'flag_work_phone',\n",
    "    'flag_phone', \n",
    "    'flag_email',\n",
    "    'occupation_type'\n",
    "]\n",
    "\n",
    "numerical = [\n",
    "    'cnt_children',\n",
    "    'amt_income_total',\n",
    "    'cnt_fam_members'\n",
    "]\n",
    "\n",
    "other = [\n",
    "    'is_unemployed',\n",
    "    'education_level'\n",
    "]\n",
    "\n",
    "# define X and y datasets\n",
    "X = df[categorical + numerical + other]\n",
    "y = df[['is_good']]\n",
    "\n",
    "# split between train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize encoder for categorical vars\n",
    "enc = OneHotEncoder(drop='first', sparse=False)\n",
    "\n",
    "# fit transform encoder to train data\n",
    "X_train_categorical = pd.DataFrame(enc.fit_transform(X_train[categorical]), index=X_train.index, columns=enc.get_feature_names_out())\n",
    "\n",
    "# transform encoder to test data\n",
    "X_test_categorical = pd.DataFrame(enc.transform(X_test[categorical]), index=X_test.index, columns=enc.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize scaler for numerical vars\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# fit transform scaler to train data\n",
    "X_train_numerical = pd.DataFrame(scaler.fit_transform(X_train[numerical]), index=X_train.index, columns=numerical)\n",
    "\n",
    "# transform scaler to test data\n",
    "X_test_numerical = pd.DataFrame(scaler.transform(X_test[numerical]), index=X_test.index, columns=numerical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate numerical and categorical vars\n",
    "X_train_normal = pd.concat((X_train_numerical, X_train_categorical, X_train[other]), axis=1)\n",
    "X_test_normal = pd.concat((X_test_numerical, X_test_categorical, X_test[other]), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictive Analysis"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "30f29e61a2d73c2e554431b8182b4498d12c3b46a18a17a405eb97c1abf872bc"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
